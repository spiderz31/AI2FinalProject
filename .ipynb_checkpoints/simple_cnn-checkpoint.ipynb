{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './train'\n",
    "test_dir = './val_and_test'\n",
    "checkpoint_dir = './checkpoints'\n",
    "result_path = './submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"datasets\" below open your images and preprocess them\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    train_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    test_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data loaders below collect your images and put them into batches to feed the neural network \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=40, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN architecture\n",
    "class Simple_CNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(Simple_CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=11, stride=4, padding=2),\n",
    "#            nn.ReLU(inplace=True),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(8, 8, kernel_size=3, padding=2),\n",
    "#            nn.ReLU(inplace=True),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            #additional layer\n",
    "#            nn.Conv2d(8, 8, kernel_size=3, padding=2),\n",
    "#            nn.ReLU(inplace=True),\n",
    "#            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "#            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
    "#            nn.ReLU(inplace=True),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "#             nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16, 16),\n",
    "#            nn.ReLU(inplace=True),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Linear(16, 16),\n",
    "#            nn.ReLU(inplace=True),\n",
    "            nn.LeakyReLU(negative_slope=0.01,inplace=True),\n",
    "            nn.Linear(16, num_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "#        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(output, target):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    correct_k = correct[0].view(-1).float().sum(0, keepdim=True)\n",
    "\n",
    "    return correct_k.mul_(1.0 / batch_size).data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, criterion, optimizer, val_num):\n",
    "    loss_recorder = AverageMeter() # record the loss of each batch to get the overall loss\n",
    "    accuracy_recorder = AverageMeter() # record the accuracy of each batch to get the overall accuracy\n",
    "    \n",
    "    model.train() # switch to train mode\n",
    "    for i, (input, target) in enumerate(data_loader):\n",
    "        if i != val_num:\n",
    "            #input, target = Variable(input), Variable(target)\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            optimizer.zero_grad() # clear the gradients computed before\n",
    "            loss.backward() # compute the gradients using backward propagation\n",
    "            optimizer.step() # update the parameters of the network\n",
    "\n",
    "            accuracy = get_accuracy(output, target)\n",
    "            loss = loss.cpu().data[0] # convert from pytorch variable to a python float number\n",
    "            print('Batch {}:\\tloss: {:.05f}\\t accuracy: {:.05f}'.format(i+1, loss, accuracy))\n",
    "            loss_recorder.update(loss, input.size(0))\n",
    "            accuracy_recorder.update(accuracy, input.size(0))\n",
    "    return loss_recorder.avg, accuracy_recorder.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data_loader, criterion, val_num):\n",
    "    \n",
    "    loss_recorder = AverageMeter() # record the loss of each batch to get the overall loss\n",
    "    accuracy_recorder = AverageMeter() # record the accuracy of each batch to get the overall accuracy\n",
    "    model.eval() # switch to evaluation mode\n",
    "    for i, (input, target) in enumerate(data_loader):\n",
    "        if i==val_num:\n",
    "            #input, target = Variable(input, volatile=True), Variable(target)\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            accuracy = get_accuracy(output, target)\n",
    "            loss = loss.cpu().data[0] # convert from pytorch variable to a python float number\n",
    "            print('Batch {}:\\tloss: {:.05f}\\t accuracy: {:.05f}'.format(i+1, loss, accuracy))\n",
    "            loss_recorder.update(loss, input.size(0))\n",
    "            accuracy_recorder.update(accuracy, input.size(0))\n",
    "    return loss_recorder.avg, accuracy_recorder.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename):\n",
    "    torch.save(state, filename)\n",
    "    print('A checkpoint was saved to {}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltLoss(train, val, num_epochs):\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(num_epochs)+1, train)\n",
    "    plt.plot(np.arange(num_epochs)+1, val)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['train', 'val'])\n",
    "    plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltAcc(train, val, num_epochs):\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(num_epochs)+1, train)\n",
    "    plt.plot(np.arange(num_epochs)+1, val)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(['train', 'val'])\n",
    "    plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResNetModel():\n",
    "    model_conv=torchvision.models.resnet50(pretrained=True)\n",
    "    ## Freezing all layers\n",
    "    for params in model_conv.parameters():\n",
    "        params.requires_grad = False\n",
    "    ## Change the last layer\n",
    "    num_ftrs = model_conv.fc.in_features\n",
    "    model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "    return model_conv\n",
    "\n",
    "\n",
    "def getResNetModelFineTuning():\n",
    "    model_conv=torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "    ## Freezing the first few layers. Here I am freezing the first 7 layers \n",
    "    ct = 0\n",
    "    for name, child in model_conv.named_children():\n",
    "        ct += 1\n",
    "        if ct < 7:\n",
    "            for name2, params in child.named_parameters():\n",
    "                params.requires_grad = False\n",
    "                \n",
    "    ## Change the last layer\n",
    "    num_ftrs = model_conv.fc.in_features\n",
    "    model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "    \n",
    "    return model_conv\n",
    "\n",
    "def getVGGModel():\n",
    "    \n",
    "    model_conv = torchvision.models.vgg19(pretrained=True)\n",
    "\n",
    "    # Number of filters in the bottleneck layer\n",
    "    num_ftrs = model_conv.classifier[6].in_features\n",
    "    # convert all the layers to list and remove the last one\n",
    "    features = list(model_conv.classifier.children())[:-1]\n",
    "    ## Add the last layer based on the num of classes in our dataset\n",
    "    features.extend([nn.Linear(num_ftrs, 2)])\n",
    "    ## convert it into container and add it to our model class.\n",
    "    model_conv.classifier = nn.Sequential(*features)  \n",
    "\n",
    "    return model_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initModel(modelID):\n",
    "    if modelID==1:\n",
    "        model=Simple_CNN()\n",
    "        model = model.to(device)\n",
    "        # Create a ADAM optimizer\n",
    "        opt=torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    elif modelID==2:\n",
    "        model=getResNetModel()\n",
    "        model = model.to(device)\n",
    "        opt=torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "    elif modelID==3:\n",
    "        model=getResNetModelFineTuning()\n",
    "        model = model.to(device)\n",
    "        opt=torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "    else:\n",
    "        model=getVGGModel()\n",
    "        model = model.to(device)\n",
    "        opt=torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    return model, train_losses, train_accuracies, val_losses, val_accuracies, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochsModel(model, optimizer, val, maxAcc, train_losses, train_accuracies, val_losses, val_accuracies, mdlID):\n",
    "    print('---- train ----')\n",
    "    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, val)\n",
    "    print('Avg Loss: {:.05f}\\tAvg Accuracy: {:.05f}'.format(train_loss, train_accuracy))\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    print('-- validate --')\n",
    "    val_loss, val_accuracy = validate(model, train_loader, criterion, val)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    save_checkpoint(model.state_dict(), checkpoint_dir+'/checkpoint{}_epoch{}.pk'.format(mdlID,epoch))\n",
    "    if val_accuracy > maxAcc:\n",
    "        bstMdl=copy.deepcopy(model.state_dict())\n",
    "        maxAcc=val_accuracy\n",
    "        valNum=val\n",
    "    elif val_accuracy == maxAcc:\n",
    "        n=random.randrange(1,2)\n",
    "        if n==2:\n",
    "            bstMdl=copy.deepcopy(model.state_dict())\n",
    "            maxAcc=val_accuracy\n",
    "            valNum=val\n",
    "    return model, train_losses, train_accuracies, val_losses, val_accuracies, bstMdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation 1\n",
      "\n",
      "Epoch 1\n",
      "---- train ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pedro\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2:\tloss: 0.68904\t accuracy: 0.55000\n",
      "Batch 3:\tloss: 0.72150\t accuracy: 0.42500\n",
      "Batch 4:\tloss: 0.68215\t accuracy: 0.57500\n",
      "Batch 5:\tloss: 0.69494\t accuracy: 0.52500\n",
      "Avg Loss: 0.69691\tAvg Accuracy: 0.51875\n",
      "-- validate --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pedro\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\tloss: 0.67592\t accuracy: 0.60000\n",
      "A checkpoint was saved to ./checkpoints/checkpoint1_epoch1.pk\n",
      "\n",
      "Epoch 2\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.69475\t accuracy: 0.52500\n",
      "Batch 3:\tloss: 0.70078\t accuracy: 0.50000\n",
      "Batch 4:\tloss: 0.68822\t accuracy: 0.55000\n",
      "Batch 5:\tloss: 0.71235\t accuracy: 0.45000\n",
      "Avg Loss: 0.69902\tAvg Accuracy: 0.50625\n",
      "-- validate --\n",
      "Batch 1:\tloss: 0.67619\t accuracy: 0.60000\n",
      "A checkpoint was saved to ./checkpoints/checkpoint1_epoch2.pk\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a40862f470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a4085fa828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 0m 21s\n",
      "Validation 2\n",
      "\n",
      "Epoch 1\n",
      "---- train ----\n",
      "Batch 1:\tloss: 0.69191\t accuracy: 0.60000\n",
      "Batch 3:\tloss: 0.69488\t accuracy: 0.45000\n",
      "Batch 4:\tloss: 0.69286\t accuracy: 0.52500\n",
      "Batch 5:\tloss: 0.69134\t accuracy: 0.60000\n",
      "Avg Loss: 0.69275\tAvg Accuracy: 0.54375\n",
      "-- validate --\n",
      "Batch 2:\tloss: 0.69521\t accuracy: 0.42500\n",
      "A checkpoint was saved to ./checkpoints/checkpoint1_epoch1.pk\n",
      "\n",
      "Epoch 2\n",
      "---- train ----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-501d41e42350>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nEpoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrn_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrn_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbstMdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochsModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxAcc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrn_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrn_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mpltLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mpltAcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-3a1f1e857111>\u001b[0m in \u001b[0;36mepochsModel\u001b[1;34m(model, optimizer, val, maxAcc, train_losses, train_accuracies, val_losses, val_accuracies, mdlID)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mepochsModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxAcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_accuracies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdlID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'---- train ----'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Avg Loss: {:.05f}\\tAvg Accuracy: {:.05f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-4e032be803ef>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, criterion, optimizer, val_num)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# switch to train mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mval_num\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;31m#input, target = Variable(input), Variable(target)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# ensure that the worker exits on process exit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0m_update_worker_pids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs=50\n",
    "valNum=5\n",
    "bestModels=[]\n",
    "for mdl in range(1,4):\n",
    "    for val in range(0,valNum):\n",
    "        since = time.time()\n",
    "        model, trn_loss, trn_acc, val_loss, val_acc, opt=initModel(mdl)\n",
    "        maxAcc=0.0\n",
    "        print('Validation {}'.format(val+1))\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            print('\\nEpoch', epoch)\n",
    "            model,trn_loss,trn_acc,val_loss,val_acc,bstMdl=epochsModel(model,opt,val,maxAcc,trn_loss,trn_acc,val_loss,val_acc,mdl)\n",
    "        pltLoss(trn_loss, val_loss, num_epochs)\n",
    "        pltAcc(trn_acc, val_acc, num_epochs)\n",
    "        bestModels.append(bstMdl)\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48125000298023224\n"
     ]
    }
   ],
   "source": [
    "print(train_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a model that you like best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefered_checkpoint = 'C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch50.pk'\n",
    "model.load_state_dict(torch.load(prefered_checkpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let your AI automatically recognize if there are birds in each images in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:04<00:00, 49.16it/s]\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "preds = []\n",
    "model.eval()\n",
    "for i, (input, target) in enumerate(tqdm(test_loader)):\n",
    "    input, target = Variable(input, volatile=True), Variable(target)\n",
    "    output = bstmdl(input)\n",
    "    confidence = nn.functional.softmax(output, dim=1)\n",
    "    confidence = confidence.cpu().data[0].numpy()\n",
    "    if confidence[0] >= 0.5: # If the network predicts that the image contains a bird\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "    preds.append(pred)\n",
    "    \n",
    "    # Get the file name of the current image\n",
    "    image = test_dataset.imgs[i]\n",
    "    image = os.path.basename(image[0])\n",
    "    images.append(image)\n",
    "submission = pd.DataFrame({'image': images, 'has_bird': preds}, columns=['image', 'has_bird'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the first rows of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>has_bird</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000.JPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002.JPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  has_bird\n",
       "0  0000.JPG         1\n",
       "1  0001.JPG         0\n",
       "2  0002.JPG         1\n",
       "3  0003.JPG         0\n",
       "4  0004.JPG         0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(result_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
