{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = 'C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/train'\n",
    "test_dir = 'C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/val_and_test'\n",
    "checkpoint_dir = 'C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints'\n",
    "result_path = 'C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The \"datasets\" below open your images and preprocess them\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    train_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    test_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The data loaders below collect your images and put them into batches to feed the neural network \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=40, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a simple CNN architecture\n",
    "class Simple_CNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(Simple_CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=11, stride=4, padding=2),\n",
    "#            nn.ReLU(inplace=True),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(8, 8, kernel_size=3, padding=2),\n",
    "#            nn.ReLU(inplace=True),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            #additional layer\n",
    "#            nn.Conv2d(8, 8, kernel_size=3, padding=2),\n",
    "#            nn.ReLU(inplace=True),\n",
    "#            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "#            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
    "#            nn.ReLU(inplace=True),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "#             nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16, 16),\n",
    "#            nn.ReLU(inplace=True),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Linear(16, 16),\n",
    "#            nn.ReLU(inplace=True),\n",
    "            nn.LeakyReLU(negative_slope=0.01,inplace=True),\n",
    "            nn.Linear(16, num_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "#        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a simple CNN\n",
    "model = Simple_CNN()\n",
    "\n",
    "# Create a ADAM optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(output, target):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    correct_k = correct[0].view(-1).float().sum(0, keepdim=True)\n",
    "\n",
    "    return correct_k.mul_(1.0 / batch_size).data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, data_loader, criterion, optimizer, val_num):\n",
    "    loss_recorder = AverageMeter() # record the loss of each batch to get the overall loss\n",
    "    accuracy_recorder = AverageMeter() # record the accuracy of each batch to get the overall accuracy\n",
    "    \n",
    "    model.train() # switch to train mode\n",
    "    for i, (input, target) in enumerate(data_loader):\n",
    "        if i != val_num:\n",
    "            input, target = Variable(input), Variable(target)\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            optimizer.zero_grad() # clear the gradients computed before\n",
    "            loss.backward() # compute the gradients using backward propagation\n",
    "            optimizer.step() # update the parameters of the network\n",
    "\n",
    "            accuracy = get_accuracy(output, target)\n",
    "            loss = loss.cpu().data[0] # convert from pytorch variable to a python float number\n",
    "            print('Batch {}:\\tloss: {:.05f}\\t accuracy: {:.05f}'.format(i+1, loss, accuracy))\n",
    "            loss_recorder.update(loss, input.size(0))\n",
    "            accuracy_recorder.update(accuracy, input.size(0))\n",
    "    return loss_recorder.avg, accuracy_recorder.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(model, data_loader, criterion, val_num):\n",
    "    \n",
    "    loss_recorder = AverageMeter() # record the loss of each batch to get the overall loss\n",
    "    accuracy_recorder = AverageMeter() # record the accuracy of each batch to get the overall accuracy\n",
    "    model.eval() # switch to evaluation mode\n",
    "    for i, (input, target) in enumerate(data_loader):\n",
    "        if i==val_num:\n",
    "            input, target = Variable(input, volatile=True), Variable(target)\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            accuracy = get_accuracy(output, target)\n",
    "            loss = loss.cpu().data[0] # convert from pytorch variable to a python float number\n",
    "            print('Batch {}:\\tloss: {:.05f}\\t accuracy: {:.05f}'.format(i+1, loss, accuracy))\n",
    "            loss_recorder.update(loss, input.size(0))\n",
    "            accuracy_recorder.update(accuracy, input.size(0))\n",
    "    return loss_recorder.avg, accuracy_recorder.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename):\n",
    "    torch.save(state, filename)\n",
    "    print('A checkpoint was saved to {}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pltLoss(train, val, num_epochs):\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(num_epochs)+1, train)\n",
    "    plt.plot(np.arange(num_epochs)+1, val)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['train', 'val'])\n",
    "    plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pltAcc(train, val, num_epochs):\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(num_epochs)+1, train)\n",
    "    plt.plot(np.arange(num_epochs)+1, val)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(['train', 'val'])\n",
    "    plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation 1\n",
      "\n",
      "Epoch 1\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.70784\t accuracy: 0.45000\n",
      "Batch 3:\tloss: 0.69342\t accuracy: 0.52500\n",
      "Batch 4:\tloss: 0.69337\t accuracy: 0.52500\n",
      "Batch 5:\tloss: 0.70336\t accuracy: 0.47500\n",
      "-- validate --\n",
      "Batch 1:\tloss: 0.69808\t accuracy: 0.50000\n",
      "A checkpoint was saved to C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch1.pk\n",
      "\n",
      "Epoch 2\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.69810\t accuracy: 0.50000\n",
      "Batch 3:\tloss: 0.69838\t accuracy: 0.50000\n",
      "Batch 4:\tloss: 0.69309\t accuracy: 0.52500\n",
      "Batch 5:\tloss: 0.70341\t accuracy: 0.47500\n",
      "-- validate --\n",
      "Batch 1:\tloss: 0.71350\t accuracy: 0.42500\n",
      "A checkpoint was saved to C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch2.pk\n",
      "\n",
      "Epoch 3\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.69300\t accuracy: 0.52500\n",
      "Batch 3:\tloss: 0.69842\t accuracy: 0.50000\n",
      "Batch 4:\tloss: 0.71846\t accuracy: 0.40000\n",
      "Batch 5:\tloss: 0.68301\t accuracy: 0.57500\n",
      "-- validate --\n",
      "Batch 1:\tloss: 0.70326\t accuracy: 0.47500\n",
      "A checkpoint was saved to C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch3.pk\n",
      "\n",
      "Epoch 4\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.67844\t accuracy: 0.60000\n",
      "Batch 3:\tloss: 0.69849\t accuracy: 0.50000\n",
      "Batch 4:\tloss: 0.68780\t accuracy: 0.55000\n",
      "Batch 5:\tloss: 0.72333\t accuracy: 0.37500\n",
      "-- validate --\n",
      "Batch 1:\tloss: 0.70814\t accuracy: 0.45000\n",
      "A checkpoint was saved to C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch4.pk\n",
      "\n",
      "Epoch 5\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.69354\t accuracy: 0.52500\n",
      "Batch 3:\tloss: 0.71325\t accuracy: 0.42500\n",
      "Batch 4:\tloss: 0.69786\t accuracy: 0.50000\n",
      "Batch 5:\tloss: 0.68323\t accuracy: 0.57500\n",
      "-- validate --\n",
      "Batch 1:\tloss: 0.69819\t accuracy: 0.50000\n",
      "A checkpoint was saved to C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch5.pk\n",
      "\n",
      "Epoch 6\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.68298\t accuracy: 0.57500\n",
      "Batch 3:\tloss: 0.71351\t accuracy: 0.42500\n",
      "Batch 4:\tloss: 0.69813\t accuracy: 0.50000\n",
      "Batch 5:\tloss: 0.68318\t accuracy: 0.57500\n",
      "-- validate --\n",
      "Batch 1:\tloss: 0.72299\t accuracy: 0.37500\n",
      "A checkpoint was saved to C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch6.pk\n",
      "\n",
      "Epoch 7\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.68794\t accuracy: 0.55000\n",
      "Batch 3:\tloss: 0.71824\t accuracy: 0.40000\n",
      "Batch 4:\tloss: 0.68358\t accuracy: 0.57500\n",
      "Batch 5:\tloss: 0.68341\t accuracy: 0.57500\n",
      "-- validate --\n",
      "Batch 1:\tloss: 0.68823\t accuracy: 0.55000\n",
      "A checkpoint was saved to C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch7.pk\n",
      "\n",
      "Epoch 8\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.70279\t accuracy: 0.47500\n",
      "Batch 3:\tloss: 0.70839\t accuracy: 0.45000\n",
      "Batch 4:\tloss: 0.68342\t accuracy: 0.57500\n",
      "Batch 5:\tloss: 0.70835\t accuracy: 0.45000\n",
      "-- validate --\n",
      "Batch 1:\tloss: 0.69347\t accuracy: 0.52500\n",
      "A checkpoint was saved to C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch8.pk\n",
      "\n",
      "Epoch 9\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.68857\t accuracy: 0.55000\n",
      "Batch 3:\tloss: 0.70840\t accuracy: 0.45000\n",
      "Batch 4:\tloss: 0.68787\t accuracy: 0.55000\n",
      "Batch 5:\tloss: 0.69328\t accuracy: 0.52500\n",
      "-- validate --\n",
      "Batch 1:\tloss: 0.68358\t accuracy: 0.57500\n",
      "A checkpoint was saved to C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch9.pk\n",
      "\n",
      "Epoch 10\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.69301\t accuracy: 0.52500\n",
      "Batch 3:\tloss: 0.67336\t accuracy: 0.62500\n",
      "Batch 4:\tloss: 0.71832\t accuracy: 0.40000\n",
      "Batch 5:\tloss: 0.70847\t accuracy: 0.45000\n",
      "-- validate --\n",
      "Batch 1:\tloss: 0.71792\t accuracy: 0.40000\n",
      "A checkpoint was saved to C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch10.pk\n",
      "\n",
      "Epoch 11\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.70844\t accuracy: 0.45000\n",
      "Batch 3:\tloss: 0.67270\t accuracy: 0.62500\n",
      "Batch 4:\tloss: 0.71810\t accuracy: 0.40000\n",
      "Batch 5:\tloss: 0.68830\t accuracy: 0.55000\n",
      "-- validate --\n",
      "Batch 1:\tloss: 0.70339\t accuracy: 0.47500\n",
      "A checkpoint was saved to C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch11.pk\n",
      "\n",
      "Epoch 12\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.66822\t accuracy: 0.65000\n",
      "Batch 3:\tloss: 0.69284\t accuracy: 0.52500\n",
      "Batch 4:\tloss: 0.70319\t accuracy: 0.47500\n",
      "Batch 5:\tloss: 0.71860\t accuracy: 0.40000\n",
      "-- validate --\n",
      "Batch 1:\tloss: 0.69327\t accuracy: 0.52500\n",
      "A checkpoint was saved to C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch12.pk\n",
      "\n",
      "Epoch 13\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.70829\t accuracy: 0.45000\n",
      "Batch 3:\tloss: 0.70329\t accuracy: 0.47500\n",
      "Batch 4:\tloss: 0.69837\t accuracy: 0.50000\n",
      "Batch 5:\tloss: 0.68813\t accuracy: 0.55000\n",
      "-- validate --\n",
      "Batch 1:\tloss: 0.67825\t accuracy: 0.60000\n",
      "A checkpoint was saved to C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch13.pk\n",
      "\n",
      "Epoch 14\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.70343\t accuracy: 0.47500\n",
      "Batch 3:\tloss: 0.70394\t accuracy: 0.47500\n",
      "Batch 4:\tloss: 0.69785\t accuracy: 0.50000\n",
      "Batch 5:\tloss: 0.69789\t accuracy: 0.50000\n",
      "-- validate --\n",
      "Batch 1:\tloss: 0.70853\t accuracy: 0.45000\n",
      "A checkpoint was saved to C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch14.pk\n",
      "\n",
      "Epoch 15\n",
      "---- train ----\n",
      "Batch 2:\tloss: 0.70343\t accuracy: 0.47500\n",
      "Batch 3:\tloss: 0.67789\t accuracy: 0.60000\n",
      "Batch 4:\tloss: 0.73344\t accuracy: 0.32500\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at C:\\Miniconda2\\conda-bld\\pytorch-cpu_1519449358620\\work\\torch\\lib\\TH\\THGeneral.c:253",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-c76e636ba8a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'---- train ----'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mtrain_accuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-0e698700b397>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, criterion, optimizer, val_num)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mval_num\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-0373a49d536d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m         )\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m#        x = self.maxpool(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 282\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0m_pair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 torch.backends.cudnn.deterministic, torch.backends.cudnn.enabled)\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at C:\\Miniconda2\\conda-bld\\pytorch-cpu_1519449358620\\work\\torch\\lib\\TH\\THGeneral.c:253"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "valNum=5\n",
    "maxAcc=0.0\n",
    "\n",
    "for val in range(0,valNum):\n",
    "    print('Validation {}'.format(val+1))\n",
    "    model = Simple_CNN()\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        print('\\nEpoch', epoch)\n",
    "\n",
    "        print('---- train ----')\n",
    "        train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, val)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        print('-- validate --')\n",
    "        val_loss, val_accuracy = validate(model, train_loader, criterion, val)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        save_checkpoint(model.state_dict(), checkpoint_dir+'/checkpoint_epoch{}.pk'.format(epoch))\n",
    "        if val_accuracy > maxAcc:\n",
    "            bstMdl=copy.deepcopy(model.state_dict())\n",
    "            maxAcc=val_accuracy\n",
    "            valNum=val\n",
    "        elif val_accuracy == maxAcc:\n",
    "            n=random.randrange(1,2)\n",
    "            if n==2:\n",
    "                bstMdl=copy.deepcopy(model.state_dict())\n",
    "                maxAcc=val_accuracy\n",
    "                valNum=val\n",
    "    pltLoss(train_losses, val_losses, num_epochs)\n",
    "    pltAcc(train_accuracies, val_accuracies, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a model that you like best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefered_checkpoint = 'C:/Users/showe/Documents/masters/SP18/CS8750/Project/code/data/checkpoints/checkpoint_epoch50.pk'\n",
    "model.load_state_dict(torch.load(prefered_checkpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let your AI automatically recognize if there are birds in each images in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:04<00:00, 49.16it/s]\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "preds = []\n",
    "model.eval()\n",
    "for i, (input, target) in enumerate(tqdm(test_loader)):\n",
    "    input, target = Variable(input, volatile=True), Variable(target)\n",
    "    output = bstmdl(input)\n",
    "    confidence = nn.functional.softmax(output, dim=1)\n",
    "    confidence = confidence.cpu().data[0].numpy()\n",
    "    if confidence[0] >= 0.5: # If the network predicts that the image contains a bird\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "    preds.append(pred)\n",
    "    \n",
    "    # Get the file name of the current image\n",
    "    image = test_dataset.imgs[i]\n",
    "    image = os.path.basename(image[0])\n",
    "    images.append(image)\n",
    "submission = pd.DataFrame({'image': images, 'has_bird': preds}, columns=['image', 'has_bird'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the first rows of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>has_bird</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000.JPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002.JPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  has_bird\n",
       "0  0000.JPG         1\n",
       "1  0001.JPG         0\n",
       "2  0002.JPG         1\n",
       "3  0003.JPG         0\n",
       "4  0004.JPG         0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(result_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
